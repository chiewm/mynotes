# 正则化与交叉验证

## 1.5.1 正则化
模型选择的典型方法是正则化（regularization）。
结构风险最小化（structural risk minimization， SRM），等价于正则化（regularization）。结构风险在经验风险上加上表示模型复杂度的正则化项（regularizer）或罚项（penalty term）。


$$
\min_{f \in \digamma} \frac {1} {N} \sum ^N _{i=1} L (y_i, f(x_i)) + \lambda J (f)
$$

其中 $J(f)$ 为模型的复杂度，是定义在假设空间的 $\digamma$ 上的泛函。模型 $f$ 越复杂，复杂度 $J(f)$ 就越大，复杂度表示对复杂模型的惩罚。$\lambda \geqslant 0$ 是系数，用以权衡经验风险和模型复杂度，结构风险小需要经验风险与模型复杂度同时小。

正则化可以选不同的的形式，例如在回归问题中，损失函数是平方损失，正则化项可以是参数向量的 $L_2$ 范数：

$$
L(w) = \frac {1} {N} \sum ^N _{i=1}(f(x_i; w) - y_i) ^2 + \frac {\lambda} {2} {||w||} ^2
$$

${||w||}$ 表示参数向量的 $w$ 的 $L_2$ 范数。

或：

$$
L(w) = \frac {1} {N} \sum ^N _{i=1}(f(x_i; w) - y_i) ^2 + \frac {\lambda} {2} {||w||} _1
$$

${||w||}_1$ 表示参数向量的 $w$ 的 $L_1$ 范数。


正则化的作用是选择经验风险与模型复杂度同时小的模型。

正则化符合奥卡姆剃刀原理（Ocacam's razor）。

## 1.5.2 交叉验证
如果给定的样本数据充足，进行模型选择的一种简单方法是随机地江数据集切成三份，分为训练集（training set），验证集（validation set）和测试集（test set）。  
验证集用于模型的选择。

数据不充足时，采用交叉验证。  
交叉验证的基本思想是重复地使用数据。

1. 简单交叉验证  
将数据随机分成两份，一部分作为训练集，另一部分作为测试集（例70% 训练集，30% 测试集）；然后用训练集在各种条件下（如不同参数的个数）训练模型，从而获得不同的模型；在测试集上评估各个模型的测试误差，选出测试误差最小的模型。

2. S 折交叉验证（S-fold cross validation） 
随机将数据切分成 S 个互不相关的大小相同的自己；然后利用 S-1 个子集的数据训练模型，利用剩下的子集测试模型；将这一过程对可能的 S 种选择重复进行，最后选出 S 次评测中平均测试误差最小的模型。

3. 留一交叉验证（leave-one-out cross validation）  
S 折交叉验证的特殊情形时 S = N ， 往往在数据缺乏的情况下使用，N 时给定数据集的容量。

