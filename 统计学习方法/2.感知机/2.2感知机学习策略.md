# 2.2 感知机学习策略
## 2.2.1 数据集的线性可分性
存在某个超平面 $S$ 

$$
w \cdot x + b = 0
$$

能够将数据集的正实例点和负实例点完全正确地划分到超平面地两侧，对所有得 $y_i = +1$,y有 $w \cdot x + b > 0$ ，反之。

## 2.2.2 感知机学习策略
求误分类点到超平面 $S$ 的总距离。
首先写出输入空间 $R^n$ 中任一点 $x_{_0}$ 到超平面的距离：

$$
\frac {1} {\left \| w  \right \|} {|w \cdot x_{_i} + b |} 
$$

$\left \| w  \right \|$ 是 $w$ 的 $L_2$ 范数。

$L_2$ 范数:  

$$
\sqrt{\sum_{i=1}^{N} x_{i} ^2}
$$


其次，对于误分类的数据 $(x_i, y_i)$ 来说：

$$
-y_i(w \cdot x_i + b) >0
$$

成立。（当 $w \cdot x_i + b > 0$ 时，$y_i=-1$）
因此,误分类点 $x_i$ 到超平面 $S$ 的距离是：

$$
-\frac {1} {\left \| w  \right \|} {y_i} {(w \cdot x_{_i} + b )} 
$$

假设超平面的 $S$ 的误分类点集合为 $M$,那么所有误分类点到超平面 $S$ 的距离为：

$$
-\frac {1} {\left \| w  \right \|}\sum _{x_i \in M} ^{} {y_i} {(w \cdot x_{_i} + b )} 
$$

不考虑 $\frac {1} {||w||}$，得到感知机的损失函数。

$$
L(w, b) = -\sum _{x_i \in M} ^{} y_i(w \cdot x_i + b)
$$

